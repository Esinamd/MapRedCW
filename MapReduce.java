//MapReduce Implementation by Esinam Dake B927160
//source references: https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html,
// https://stackoverflow.com/questions/47128975/ascending-sort-based-on-values-of-the-reducer/47130876,
// https://learn.lboro.ac.uk/pluginfile.php/1660037/mod_resource/content/1/lecture05-programmingmr.pdf
//Google Storage Path - input directory: gs://hadoopbucket1234/input
//Google Storage Path - output directory: gs://hadoopbucket1234/output

import java.util.*;
import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class MapReduce {
    private static String bNumber;

      public static void main(String[] args) throws Exception{

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "n-grams");
        job.setJarByClass(MapReduce.class);
        job.setMapperClass(MRMapper.class);
        job.setCombinerClass(MRReducer.class);
        job.setReducerClass(MRReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        //input the b number when running the application to calculate the number of ngrams
        if (args[2].isEmpty()){ // setting default value to
            bNumber = "927160";
        } else {
            bNumber = args[2];
        }
        System.exit(job.waitForCompletion(true) ? 0 : 1);

    }

    //mapper class for mapreduce mapping each ngram
    public static class MRMapper extends Mapper<Object, Text, Text, IntWritable>{
        private static int n = (Integer.parseInt(bNumber)%5)+1; // (b927160 mod 5) +1 = 1
        private final static IntWritable occ = new IntWritable(n);
        private Text ngram = new Text(); //variable storing each word (ngram)

        //method for mapping
        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String words = value.toString();
            StringTokenizer itr = new StringTokenizer(words); ////old
            int m = n;
            while (m>0) {
                tokenise (context, itr, n); //tokenise the words
                String[] ary = words.split(" ");
                //turns text into a list, assumes words are split by spaces
                ArrayList<String> ary2 = new ArrayList<>();
//                for (int i = 1; i<ary.length; i++)
                for(int i = ary.length; i-- >= 1;){
                    ary2.add(ary[i]); //creating a new arraylist without the first token
                }
                words = String.join(", ", ary2); // turning the list back into a string
                words = words.replace(",",""); //removing any additional commas
                m--;
            }
        }

        //tokenise method that makes ngrams
        public void tokenise (Context context, StringTokenizer itr, int n) throws IOException, InterruptedException {
            while (itr.hasMoreTokens()) { /// old
                ArrayList<String> l = new ArrayList<>();
//                for (int i=0; i<n; i++)
                for (int i = n; i-->=0;){
                    if (itr.hasMoreTokens()){
                        l.add(itr.nextToken());
                        //adding ngrams to arraylist that changes size depending on n(generated by b-number)
                    }
                }

                ngram.set(String.valueOf(l)); ///old
                context.write(ngram, occ); // initial ngram ////old
                //mapping ngram and number of occurrences (initially one)
            } ////old

        }
    }

    //reducer class for reducing each ngram
    public static class MRReducer extends Reducer<Text, IntWritable, Text, IntWritable>{
        private IntWritable result = new IntWritable();

        private TreeMap<Text, IntWritable> alphSort = new TreeMap<Text, IntWritable>(); //using treemap to sort the ngrams alphabetically
        //method for reducing the ngrams
        public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
            int sum = 0; //variable storing number of occurrences for a particular ngram
            for (IntWritable val:values) {
                sum += val.get(); //summing the number of occurrences
            }
            result.set(sum);
//            context.write(key, result); // final ngram
            alphSort.put(key,result); //putting results into a treemap
            sorting (context);
        }

        protected void sorting (Context context) throws IOException, InterruptedException {
            Set<Map.Entry<Text,IntWritable>> set = alphSort.entrySet();
            List<Map.Entry<Text, IntWritable>> list = new ArrayList<>(set); //changing to arraylist so it can be sorted
            Collections.sort(list, new Comparator<Map.Entry<Text, IntWritable>>() {

                //method for sorting the key alphabetically
                public int compare(Map.Entry<Text, IntWritable> o1, Map.Entry<Text, IntWritable> o2) {
                    return (o2.getKey()).compareTo(o1.getKey()); //comparing key to previous key
                }
            });
            for (Map.Entry<Text, IntWritable> entry:list){
                context.write(entry.getKey(), entry.getValue()); //final values
            }
        }
    }
}
